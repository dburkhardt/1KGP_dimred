{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension reduction of genotype data\n",
    "\n",
    "This notebook is intended to explore ethnicity and population structure through dimension reduction of genotype data from the Thousand Genomes Project (1KGP). Data is available here:\n",
    "\n",
    "* http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/supporting/hd_genotype_chip/\n",
    "* http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/\n",
    "\n",
    "We will use the following files:\n",
    "* ALL.wgs.nhgri_coriell_affy_6.20140825.genotypes_has_ped.vcf.gz\n",
    "* affy_samples.20141118.panel\n",
    "* 20131219.populations.tsv\n",
    "\n",
    "t-SNE is available in sklearn but can be quite slow. Multi-core t-SNE and UMAP are only on github, as of June 2018, at the following links:\n",
    "* https://github.com/lmcinnes/umap\n",
    "* https://github.com/DmitryUlyanov/Multicore-TSNE/\n",
    "\n",
    "To install UMAP, run one of the following:\n",
    "\n",
    "```conda install -c conda-forge umap-learn```\n",
    "\n",
    "```pip install umap-learn```\n",
    "\n",
    "If neither works, please visit the UMAP github page for more detailed directions.\n",
    "\n",
    "Papers for t-SNE and UMAP can be found, respectively, at the following links:\n",
    "* https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf\n",
    "* https://arxiv.org/pdf/1802.03426.pdf\n",
    "\n",
    "This code was written by Alex Diaz-Papkovich and Simon Gravel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bokeh in /home/dan/.local/lib/python3.7/site-packages (1.2.0)\r\n",
      "Requirement already satisfied: packaging>=16.8 in /usr/lib/python3.7/site-packages (from bokeh) (19.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/lib/python3.7/site-packages (from bokeh) (2.8.0)\r\n",
      "Requirement already satisfied: numpy>=1.7.1 in /usr/lib/python3.7/site-packages (from bokeh) (1.16.3)\r\n",
      "Requirement already satisfied: pillow>=4.0 in /usr/lib/python3.7/site-packages (from bokeh) (6.0.0)\r\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/lib/python3.7/site-packages (from bokeh) (3.13)\r\n",
      "Requirement already satisfied: six>=1.5.2 in /usr/lib/python3.7/site-packages (from bokeh) (1.12.0)\r\n",
      "Requirement already satisfied: tornado>=4.3 in /usr/lib/python3.7/site-packages (from bokeh) (5.1.1)\r\n",
      "Requirement already satisfied: Jinja2>=2.7 in /usr/lib/python3.7/site-packages (from bokeh) (2.10.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/lib/python3.7/site-packages (from packaging>=16.8->bokeh) (2.4.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/lib/python3.7/site-packages (from Jinja2>=2.7->bokeh) (1.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --user bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries. \n",
    "# Generate images in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import gzip\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from ipywidgets import interact\n",
    "import bokeh\n",
    "import bokeh.io\n",
    "from bokeh.io import push_notebook\n",
    "from bokeh.plotting import figure, show, save, output_notebook, output_file\n",
    "\n",
    "# Import colour palettes for later on\n",
    "from bokeh.palettes import Category20b\n",
    "from bokeh.palettes import Purples\n",
    "from bokeh.palettes import Greens\n",
    "from bokeh.palettes import YlOrBr\n",
    "from bokeh.palettes import YlOrRd\n",
    "from bokeh.palettes import PuOr\n",
    "from bokeh.palettes import RdGy\n",
    "\n",
    "# Dimension reduction tools\n",
    "from sklearn.decomposition import PCA as PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your parent directory. This is where your 1KGP files are stored\n",
    "data_dir = '/home/dan/data/burkhardt/1000_genomes/'\n",
    "\n",
    "# These are the names of the files we use\n",
    "vcf_name = 'ALL.wgs.nhgri_coriell_affy_6.20140825.genotypes_has_ped.vcf.gz'\n",
    "pop_desc_name = '20131219.populations.tsv'\n",
    "pop_file_name = 'affy_samples.20141118.panel'\n",
    "\n",
    "vcf_file = os.path.join(data_dir, vcf_name)\n",
    "population_description_file = os.path.join(data_dir, pop_desc_name)\n",
    "population_file = os.path.join(data_dir, pop_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to read in the SNP data. Assign every SNP a value of {0,1,2} relative to reference genome.\n",
    "from collections import Counter\n",
    "\n",
    "class snp(object):\n",
    "\n",
    "    def __init__(self, line, select=False, autosome_only =True):\n",
    "        \"\"\"The initialization method takes in a line from the vcf file, as a string, \n",
    "        and records the relevant information. \n",
    "        line: a string from a vcf file\n",
    "        select: a list of positions of individuals to be analyzed, where positions run from 0 to \n",
    "        nInd-1, the number of individuals\n",
    "        \"\"\" \n",
    "        \n",
    "        split_line = line.split()  #  First break down the line into a list of each field\n",
    "        \n",
    "        self.failed = False  # A label that we will set to True if something goes wrong.\n",
    "        \n",
    "        if line.startswith('#'):\n",
    "            self.failed = True\n",
    "            self.failure_cause = \"line was a header line, not a snp\"\n",
    "            return\n",
    "        \n",
    "        if len(split_line)<=5:\n",
    "            self.failed = True\n",
    "            self.failure_cause = \"incorrectly formatted line, should have at least 5 fields \" + line\n",
    "            return\n",
    "          \n",
    "        self.chrom = split_line[0]\n",
    "        if autosome_only:\n",
    "            if self.chrom not in [\"%d\" % (i,) for i in range(1,23)]:\n",
    "                self.failed = True\n",
    "                self.failure_cause = \"not recognized as an autosome while autosome_only set to True\"\n",
    "                return\n",
    "        \n",
    "        self.chrom = int(split_line[0]) # Chromosome (numbered)\n",
    "        self.position = int(split_line[1])  # The coordinates of the snp\n",
    "        self.rid = split_line[2] # Name/Record ID\n",
    "        self.ref_allele = split_line[3]\n",
    "        self.alt_allele = split_line[4] # The alterate allele according to the vcf; also a string \n",
    "        # Only accept snps in ACGT. \n",
    "        if self.ref_allele not in [\"A\",\"C\",\"G\",\"T\"] or self.alt_allele not in [\"A\",\"C\",\"G\",\"T\"]:\n",
    "            self.failed = True\n",
    "            self.failure_cause = \"ref or alt not in ACGT\"\n",
    "            return\n",
    "        self.filter = split_line[6]  # See vcf format specifications for the interpretation of \n",
    "                                    # the filter field\n",
    "        if self.filter not in ['PASS', '.'] :  # PASS indicates a SNP that passed all QC filters.\n",
    "            self.failed = True\n",
    "            self.failure_cause = self.filter\n",
    "            return\n",
    "              \n",
    "        self.genotype_strings = split_line[9:]\n",
    "\n",
    "        # Prepare a list that will contain the transformed genotypes. \n",
    "        # Since we already know how long the list will be, it makes sense \n",
    "        # to create an array of zeros of the same length as self.gtypes, \n",
    "        \n",
    "        self.genotype_array = np.zeros(len(self.genotype_strings), dtype = np.int8)             \n",
    "\n",
    "        # Count the number of each genotype. \n",
    "        # There may be different strings giving the same genotype so we increment the \n",
    "        # counts found so far for the genotype by the number of times the  \n",
    "        # For example, \"0/0\" and \"0\\0\" give homref, and \"0|1\" and \"1|0\" give het\n",
    "        \n",
    "        n_missing = 0\n",
    "        for index,genotype_string in enumerate(self.genotype_strings):\n",
    "            if genotype_string == './.':\n",
    "                n_missing +=1 \n",
    "                self.genotype_array[index]=-1\n",
    "                continue # missing data will be left as 0\n",
    "            allele_0 = genotype_string[0] # Get the first allele (as a string)\n",
    "            allele_1 = genotype_string[2]\n",
    "            if (allele_0=='1' and allele_1=='1'): # Use rstrip because windows machines will occasionally have extra \\n\n",
    "                self.genotype_array[index]=2\n",
    "            elif ((allele_0=='0' and allele_1=='1') or (allele_0=='1' and allele_1=='0')):\n",
    "                self.genotype_array[index]=1   \n",
    "            elif (allele_0=='0' and allele_1=='0'):\n",
    "                # The array was initialized to zero, so nothing to do here!\n",
    "                continue\n",
    "            else:\n",
    "                print((\"unknown genotype\", genotype_string))\n",
    "                self.failed=True\n",
    "                self.failedreason=\"unknown genotype\"\n",
    "                return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following step imports the genotype data. It is not particularly efficient so will take a few minutes even if we skip some of the lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: not recognized as an autosome while autosome_only set to True\n",
      "Failed: not recognized as an autosome while autosome_only set to True\n",
      "Failed: not recognized as an autosome while autosome_only set to True\n",
      "Failed: not recognized as an autosome while autosome_only set to True\n",
      "Failed: not recognized as an autosome while autosome_only set to True\n",
      "Failed: not recognized as an autosome while autosome_only set to True\n",
      "Failed: not recognized as an autosome while autosome_only set to True\n",
      "Failed: not recognized as an autosome while autosome_only set to True\n",
      "Failed: not recognized as an autosome while autosome_only set to True\n",
      "Failed: not recognized as an autosome while autosome_only set to True\n",
      "Run time in seconds: 216.5364706516266\n"
     ]
    }
   ],
   "source": [
    "# Specify the number of lines to skip to avoid storing every line in memory\n",
    "number_of_lines_to_skip = 10\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "genotype_matrix = []  # Will contain our numerical genotype matrix. \n",
    "genotype_positions = []\n",
    "genotype_names = []\n",
    "x = 0\n",
    "error_count = 0\n",
    "\n",
    "with gzip.open(vcf_file,'rt') as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        count+=1\n",
    "        if count % number_of_lines_to_skip == 0:\n",
    "            if line.startswith(\"#\") or snp(line).failed:\n",
    "                if snp(line).failure_cause != \"line was a header line, not a snp\":\n",
    "                    error_count += 1\n",
    "                    if x < 10:\n",
    "                        print('Failed: ' + snp(line).failure_cause)\n",
    "                        x+=1\n",
    "                continue\n",
    "            \n",
    "            return_snp = snp(line)\n",
    "            genotype_matrix.append(return_snp.genotype_array)\n",
    "            genotype_names.append(return_snp.rid)\n",
    "            genotype_positions.append([return_snp.chrom, return_snp.position])\n",
    "\n",
    "end_time = time.time()\n",
    "            \n",
    "print(\"Run time in seconds: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transpose the matrix\n",
    "transposed_genotype_matrix = np.array(genotype_matrix).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code imports auxiliary data (ethnicity, continent, descriptive data, colouring, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_by_individual = defaultdict(int)\n",
    "individuals_by_population = defaultdict(list)  # A dictionary containing all the individuals in a given population\n",
    "\n",
    "for line in open(population_file,'r'):\n",
    "    split_line = line.split()\n",
    "    if split_line[0] == 'sample':  # header line\n",
    "        continue\n",
    "\n",
    "    sample_name = split_line[0]\n",
    "    population_name = split_line[1]\n",
    "    population_by_individual[sample_name] = population_name\n",
    "    individuals_by_population[population_name].append(sample_name) \n",
    "\n",
    "populations = list(individuals_by_population.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the place where you put the population name file.\n",
    "name_by_code = {}  # A dictionary giving the full name of each population code\n",
    "pop_by_continent = {}  # A dictionary giving the code of each population within a continent  \n",
    "continent_by_population = {}  # A dictionary giving the continent for each population code\n",
    "for line in open(population_description_file,'r'):\n",
    "    split_line = line.split('\\t')\n",
    "    if split_line[0] in ['Population Description','Total','']:  # header or footer\n",
    "        continue\n",
    "    name_by_code[split_line[1]] = split_line[0]\n",
    "    continent_by_population[split_line[1]] = split_line[2]\n",
    "    try: \n",
    "        pop_by_continent[split_line[2]].append(split_line[1])\n",
    "    except KeyError:\n",
    "        pop_by_continent[split_line[2]] = [split_line[1]]\n",
    "\n",
    "continents = list(pop_by_continent.keys()) \n",
    "    \n",
    "    \n",
    "# Populations listed by continent\n",
    "pops=[]\n",
    "for continent in continents:\n",
    "    pops.extend(pop_by_continent[continent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign colours to each ethnicity, roughly themed according to continent\n",
    "# The Category20b palette has a bunch of groups of 4 shades in the same colour range\n",
    "color_dict = {}\n",
    "for i, cont in enumerate(continents): \n",
    "    for j, pop in enumerate(pop_by_continent[cont]):\n",
    "        color_dict[pop] = Category20b[20][4*i+j%4]\n",
    "\n",
    "# Colour palette above only really supports groups of 4 so we have to manually specify a few colours for the 5th/6th\n",
    "# members of a group\n",
    "\n",
    "color_dict['CHS'] = Purples[9][4]# purple\n",
    "color_dict['STU'] = Greens[9][6] # green\n",
    "color_dict['LWK'] = PuOr[11][-1] # brown\n",
    "color_dict['MSL'] = PuOr[11][-2] # rusty brown\n",
    "color_dict['YRI'] = PuOr[11][-3] # cappucino w/ extra milk (stirred)\n",
    "color_dict['CEU'] = RdGy[11][-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in gzip.open(vcf_file,'rt'):\n",
    "    if line.startswith(\"#\"):\n",
    "        if not line.startswith(\"##\"):\n",
    "            # Extract the individuals for the population, as a list of strings\n",
    "            # Windows users may have trailing \\n characters\n",
    "            individuals = line.split()[9:]\n",
    "            # Once we've extracted the individuals, we can exit the loops. \n",
    "            break\n",
    "\n",
    "# Build a list of populations for each indiviudal in the vcf file\n",
    "lspop = []\n",
    "for ind in individuals:\n",
    "    pop = population_by_individual[ind]\n",
    "    if pop == 0:\n",
    "        lspop.append(\"missing\")\n",
    "    else:\n",
    "        lspop.append(pop)\n",
    "\n",
    "        \n",
    "indices_of_population_members = defaultdict(list)\n",
    "\n",
    "for index,individual in enumerate(individuals):\n",
    "    try:\n",
    "        indices_of_population_members[population_by_individual[individual]].append(index)\n",
    "    except KeyError: # We do not have population info for this individual\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we generate our prinicipal component projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_labels = np.zeros(transposed_genotype_matrix.shape[0], dtype=object)\n",
    "for pop in indices_of_population_members:\n",
    "    pop_labels[indices_of_population_members[pop]] = pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('../data/transposed_genotype_matrix.npz',transposed_genotype_matrix=transposed_genotype_matrix, pop_labels=pop_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
